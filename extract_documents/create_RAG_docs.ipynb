{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b529c1ba-0fc8-4cb4-a710-46c1b4cf6fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/anup/miniconda3/envs/finetune-gllm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-22 14:10:41,459] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import markdown\n",
    "from html import unescape\n",
    "from bs4 import BeautifulSoup\n",
    "from haystack import Document\n",
    "from haystack.nodes import PreProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247cdac1-e948-4cce-b494-b4c4711648b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_108347/3443310435.py:18: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  plain_text = ''.join(BeautifulSoup(html_content, \"html.parser\").findAll(text=True))\n"
     ]
    }
   ],
   "source": [
    "# Collect from GTN\n",
    "\n",
    "docs = []\n",
    "directory_path = \"../../../gtn-data/\"\n",
    "\n",
    "def read_md_file_1(path):\n",
    "    with open(path) as f:\n",
    "        content = f.read()\n",
    "        return content\n",
    "\n",
    "def read_md_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        md_content = file.read()\n",
    "    return extract_plain_text_from_md(md_content)\n",
    "\n",
    "def extract_plain_text_from_md(md_content):\n",
    "    html_content = markdown.markdown(md_content)\n",
    "    plain_text = ''.join(BeautifulSoup(html_content, \"html.parser\").findAll(text=True))\n",
    "    return plain_text.strip()\n",
    "    \n",
    "#included_content = \"/topics/statistics/tutorials/intro_deep_learning/\"\n",
    "included_content = \"/topics/\"\n",
    "\n",
    "for root, dirs, files in os.walk(directory_path):\n",
    "    for filename in files:\n",
    "        if fnmatch.fnmatch(filename, '*.md'):\n",
    "            path = os.path.join(root, filename)\n",
    "            if included_content in path:\n",
    "                s_path = path.split(\"/\")[-3:]\n",
    "                tutorial_name = \"_\".join(s_path)\n",
    "                md_plain_text = read_md_file(path)\n",
    "                pr_dict = {\"content\": md_plain_text, \"meta\": {\"name\": tutorial_name}}\n",
    "                doc = Document.from_json(json.dumps(pr_dict))\n",
    "                docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3050016-b331-4faa-ad61-91840bae3b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect from PRs\n",
    "\n",
    "# process PRs\n",
    "for json_file in glob.glob(\"../out/github_pr_page_*.json\"):\n",
    "    with open(json_file, \"r\") as fin:\n",
    "        doc_json = json.load(fin)\n",
    "        for pr in doc_json:\n",
    "            pr_text = pr[\"body\"]\n",
    "            if pr_text != None:\n",
    "                useful_text_limit = pr_text.find(\"## How to test the changes\")\n",
    "                if useful_text_limit > 0:\n",
    "                    pr_text = pr_text[:useful_text_limit].strip()\n",
    "                    pr_dict = {\"content\": pr_text, \"meta\": {\"name\": pr[\"number\"]}}\n",
    "                    doc = Document.from_json(json.dumps(pr_dict))\n",
    "                    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf46f3da-46ff-434d-9fa5-8b8510f530fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:   0%|                                                                                                                         | 0/5018 [00:00<?, ?docs/s]We found one or more sentences whose split count is higher than the split length.\n",
      "Document 765879b873e5da1f6844b2b004354251 is 15953 characters long after preprocessing, where the maximum length should be 10000. Something might be wrong with the splitting, check the document affected to prevent issues at query time. This document will be now hard-split at 10000 chars recursively.\n",
      "Preprocessing:  11%|████████████▌                                                                                                 | 572/5018 [00:02<00:15, 279.66docs/s]Document bd56adb5222bde92e6e6a446ac4125db is 18398 characters long after preprocessing, where the maximum length should be 10000. Something might be wrong with the splitting, check the document affected to prevent issues at query time. This document will be now hard-split at 10000 chars recursively.\n",
      "Preprocessing:  13%|██████████████                                                                                                | 640/5018 [00:02<00:14, 304.15docs/s]Document 4632727d14cf65552d3611c3d379e2ff is 71514 characters long after preprocessing, where the maximum length should be 10000. Something might be wrong with the splitting, check the document affected to prevent issues at query time. This document will be now hard-split at 10000 chars recursively.\n",
      "Document f4de4544390feafab7826fb379b6846f is 61514 characters long after preprocessing, where the maximum length should be 10000. Something might be wrong with the splitting, check the document affected to prevent issues at query time. This document will be now hard-split at 10000 chars recursively.\n",
      "Document 9ad9ce235fa88af47d09d1b31cc7bb76 is 51514 characters long after preprocessing, where the maximum length should be 10000. Something might be wrong with the splitting, check the document affected to prevent issues at query time. This document will be now hard-split at 10000 chars recursively.\n",
      "Document 7bfd75b67821e92587a537e8b0138361 is 41514 characters long after preprocessing, where the maximum length should be 10000. Something might be wrong with the splitting, check the document affected to prevent issues at query time. This document will be now hard-split at 10000 chars recursively.\n",
      "Document f058db145146309c1ab88d47befcfffa is 31514 characters long after preprocessing, where the maximum length should be 10000. Something might be wrong with the splitting, check the document affected to prevent issues at query time. This document will be now hard-split at 10000 chars recursively.\n",
      "Document 79ba607382954d4ec7a0dc7aa0135820 is 21514 characters long after preprocessing, where the maximum length should be 10000. Something might be wrong with the splitting, check the document affected to prevent issues at query time. This document will be now hard-split at 10000 chars recursively.\n",
      "Document 4791c539a6060c785e4b64a43e11f64 is 11514 characters long after preprocessing, where the maximum length should be 10000. Something might be wrong with the splitting, check the document affected to prevent issues at query time. This document will be now hard-split at 10000 chars recursively.\n",
      "Preprocessing:  65%|██████████████████████████████████████████████████████████████████████                                      | 3253/5018 [00:06<00:00, 1953.16docs/s]Document a54b46bd20f7cd243598211e91981972 is 27560 characters long after preprocessing, where the maximum length should be 10000. Something might be wrong with the splitting, check the document affected to prevent issues at query time. This document will be now hard-split at 10000 chars recursively.\n",
      "Document 5298a0ed77b8b25aea6acf3858f36223 is 17560 characters long after preprocessing, where the maximum length should be 10000. Something might be wrong with the splitting, check the document affected to prevent issues at query time. This document will be now hard-split at 10000 chars recursively.\n",
      "Preprocessing: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5018/5018 [00:08<00:00, 605.63docs/s]\n"
     ]
    }
   ],
   "source": [
    "processor = PreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=True,\n",
    "    split_by=\"word\",\n",
    "    split_length=200,\n",
    "    split_respect_sentence_boundary=True,\n",
    "    split_overlap=0,\n",
    "    language=\"en\",\n",
    ")\n",
    "preprocessed_docs = processor.process(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4227350-e8c7-4522-b798-28d7952762c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "\n",
    "document_store = InMemoryDocumentStore(use_bm25=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fc33ab6-0daf-4f22-b026-970a937930ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating BM25 representation...: 100%|██████████████████████████████████████████████████████████████████████████████████████| 11966/11966 [00:00<00:00, 15995.83 docs/s]\n"
     ]
    }
   ],
   "source": [
    "document_store.write_documents(preprocessed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa661ef1-9c36-4f56-85d7-08978bdf2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.nodes import BM25Retriever, PromptNode, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b35ef815-f99f-4a2b-aed4-e9aabba8c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = BM25Retriever(document_store, top_k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bba63121-1970-426b-9235-c610c299e18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "<<>> ········\n"
     ]
    }
   ],
   "source": [
    "# a good Question Answering template, adapted for the instruction format\n",
    "# (https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1)\n",
    "from haystack.nodes import PromptNode\n",
    "from getpass import getpass\n",
    "\n",
    "HF_TOKEN = getpass(\"<<>>\")\n",
    "\n",
    "qa_template = PromptTemplate(prompt=\n",
    "  \"\"\"<s>[INST] Using the information contained in the context, answer the question (using a maximum of two sentences).\n",
    "  If the answer cannot be deduced from the context, answer \\\"I don't know.\\\"\n",
    "  Context: {join(documents)};\n",
    "  Question: {query}\n",
    "  [/INST]\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ded67a44-aef2-4956-b938-a78dd6582d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "prompt_node = PromptNode(\n",
    "    model_name_or_path=model_name,\n",
    "    api_key=HF_TOKEN,\n",
    "    default_prompt_template=qa_template,\n",
    "    max_length=5500,\n",
    "    model_kwargs={\"model_max_length\":8000}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eddac64a-caa3-4ebc-97de-ba5b0822102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_node(component=retriever, name=\"retriever\", inputs=[\"Query\"])\n",
    "rag_pipeline.add_node(component=prompt_node, name=\"prompt_node\", inputs=[\"retriever\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaf02716-333d-4c60-8f04-1cb5204b899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "print_answer = lambda out: pprint(out[\"results\"][0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2604c936-bc2b-40d3-90fe-71ad662374e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The context provides instructions on how to create a pull request for a new '\n",
      " 'recipe on bioconda. It also provides information on how to install external '\n",
      " 'libraries in a conda environment and how to create a tool wrapper using '\n",
      " \"Planemo. The context does not mention the refseq_masher package, so I don't \"\n",
      " 'know if it should be installed.')\n"
     ]
    }
   ],
   "source": [
    "print_answer(rag_pipeline.run(query=\"I would suggest installing the refseq_masher package. I checked earlier, and found it in the toolshed. \\\n",
    "Please, this package will help a lot.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1a7395-622f-4353-abf5-d2d0eee0b97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c22dffe-ee0d-46cd-b364-118c72f5aaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2424c6eb-23e9-4ec6-a165-fcc783153172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
