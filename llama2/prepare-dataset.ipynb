{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64f9a3a4-d7c0-4289-bced-26661e5afd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/anup/miniconda3/envs/finetune-gllm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-12 16:36:29,056] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/anup/miniconda3/envs/finetune-gllm/lib/python3.9/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import torch\n",
    "from transformers import (LlamaTokenizer, LlamaForCausalLM)\n",
    "\n",
    "model_path = 'NousResearch/Llama-2-7b-chat-hf'\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0dff0b-3f79-4ba0-8d49-bdaaf8de32b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/centos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/centos/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "## Clean text\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import contractions\n",
    "import ftfy\n",
    "\n",
    "\n",
    "## Text preprocessing for fine tuning\n",
    "## https://www.linkedin.com/pulse/pre-processing-text-data-gpt-models-techniques-best-practices-tilix/\n",
    "## TODO: https://ftfy.readthedocs.io/en/latest/\n",
    "## TODO: Read this: https://arxiv.org/abs/2212.10496\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    clean_text = text.translate(translator)\n",
    "    return clean_text\n",
    "\n",
    "def lowercase_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "def wikitext_detokenizer(string):\n",
    "    # https://github.com/kingoflolz/mesh-transformer-jax/blob/master/create_finetune_tfrecords.py\n",
    "    # contractions\n",
    "    string = string.replace(\"s '\", \"s'\")\n",
    "    string = re.sub(r\"/' [0-9]/\", r\"/'[0-9]/\", string)\n",
    "    # number separators\n",
    "    string = string.replace(\" @-@ \", \"-\")\n",
    "    string = string.replace(\" @,@ \", \",\")\n",
    "    string = string.replace(\" @.@ \", \".\")\n",
    "    # punctuation\n",
    "    string = string.replace(\" : \", \": \")\n",
    "    string = string.replace(\" ; \", \"; \")\n",
    "    string = string.replace(\" . \", \". \")\n",
    "    string = string.replace(\" ! \", \"! \")\n",
    "    string = string.replace(\" ? \", \"? \")\n",
    "    string = string.replace(\" , \", \", \")\n",
    "    # double brackets\n",
    "    string = re.sub(r\"\\(\\s*([^\\)]*?)\\s*\\)\", r\"(\\1)\", string)\n",
    "    string = re.sub(r\"\\[\\s*([^\\]]*?)\\s*\\]\", r\"[\\1]\", string)\n",
    "    string = re.sub(r\"{\\s*([^}]*?)\\s*}\", r\"{\\1}\", string)\n",
    "    string = re.sub(r\"\\\"\\s*([^\\\"]*?)\\s*\\\"\", r'\"\\1\"', string)\n",
    "    string = re.sub(r\"'\\s*([^']*?)\\s*'\", r\"'\\1'\", string)\n",
    "    # miscellaneous\n",
    "    string = string.replace(\"= = = =\", \"====\")\n",
    "    string = string.replace(\"= = =\", \"===\")\n",
    "    string = string.replace(\"= =\", \"==\")\n",
    "    string = string.replace(\" \" + chr(176) + \" \", chr(176))\n",
    "    string = string.replace(\" \\n\", \"\\n\")\n",
    "    string = string.replace(\"\\n \", \"\\n\")\n",
    "    string = string.replace(\" N \", \" 1 \")\n",
    "    string = string.replace(\" 's\", \"'s\")\n",
    "\n",
    "    return string\n",
    "\n",
    "def clean_html_text(soup: BeautifulSoup):\n",
    "    # Process quote aside tags\n",
    "    rgx = \"<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\"\n",
    "    cleanr = re.compile(rgx)\n",
    "    cleantext = re.sub(cleanr, '', str(soup))\n",
    "\n",
    "    cleantext = re.sub(r'Screen.+KB', '', cleantext)\n",
    "    cleantext = re.sub(r'[0-9].+KB', '', cleantext)\n",
    "    cleantext = re.sub(r'Kind.+[a-z0-9]', '', cleantext)\n",
    "    cleantext = re.sub(r'Dear @.+[a-z0-9]', '', cleantext)\n",
    "    cleantext = re.sub(r'Hi @.+[a-z0-9]', '', cleantext)\n",
    "    cleantext = re.sub(r'Hello @.+[a-z0-9]', '', cleantext)\n",
    "    cleantext = re.sub(r'Cheers', '', cleantext)\n",
    "    cleantext = re.sub(r'Best .+[a-z0-9]', '', cleantext)\n",
    "    cleantext = wikitext_detokenizer(cleantext)\n",
    "    cleantext = lowercase_text(cleantext)\n",
    "    cleantext = ftfy.fix_text(cleantext)\n",
    "    tagged_sentence = nltk.tag.pos_tag(cleantext.split())\n",
    "    cleantext = [word for word, tag in tagged_sentence if tag != 'NNP' and tag != 'NNPS']\n",
    "    cleantext = \" \".join(cleantext)\n",
    "    # fix contractions\n",
    "    cleantext = contractions.fix(cleantext)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc56430a-a1c7-4cfe-9faf-1b9f2640a864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e593754-a585-47c8-9065-be3a1a1ae745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19517/1269836713.py:32: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(post_curr[\"text\"], 'html.parser')\n",
      "/tmp/ipykernel_19517/1269836713.py:32: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  soup = BeautifulSoup(post_curr[\"text\"], 'html.parser')\n",
      "/scratch/users/anup/miniconda3/envs/finetune-gllm/lib/python3.9/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n### Instruction:\\n\\nhi, i have a very ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n### Instruction:\\n\\nhi, i met an error w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n### Instruction:\\n\\nhi, i am attempting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n\\n### Instruction:\\n\\nsubmitting a job to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n\\n### Instruction:\\n\\ni need a tool which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>\\n\\n\\n### Instruction:\\n\\nhello, . i am workin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>\\n\\n\\n### Instruction:\\n\\ni have been trying t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>\\n\\n\\n### Instruction:\\n\\ni am trying to follo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>\\n\\n\\n### Instruction:\\n\\nhello. two questions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>\\n\\n\\n### Instruction:\\n\\ngood morning! i here...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1411 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          conversations\n",
       "0     \\n\\n\\n### Instruction:\\n\\nhi, i have a very ba...\n",
       "1     \\n\\n\\n### Instruction:\\n\\nhi, i met an error w...\n",
       "2     \\n\\n\\n### Instruction:\\n\\nhi, i am attempting ...\n",
       "3     \\n\\n\\n### Instruction:\\n\\nsubmitting a job to ...\n",
       "4     \\n\\n\\n### Instruction:\\n\\ni need a tool which ...\n",
       "...                                                 ...\n",
       "1406  \\n\\n\\n### Instruction:\\n\\nhello, . i am workin...\n",
       "1407  \\n\\n\\n### Instruction:\\n\\ni have been trying t...\n",
       "1408  \\n\\n\\n### Instruction:\\n\\ni am trying to follo...\n",
       "1409  \\n\\n\\n### Instruction:\\n\\nhello. two questions...\n",
       "1410  \\n\\n\\n### Instruction:\\n\\ngood morning! i here...\n",
       "\n",
       "[1411 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "with open(\"../out/data.json\") as fout:\n",
    "    raw_data = json.load(fout)\n",
    "\n",
    "user_template = \"\"\"\n",
    "\n",
    "### Instruction:\n",
    "\n",
    "{}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "system_template = \"\"\"### Response:\n",
    "\n",
    "{} \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "end_template = \"\"\"{}### End\"\"\"\n",
    "\n",
    "agg_conversations = []\n",
    "for idx_thread, thread in enumerate(raw_data):\n",
    "    conversations = \"\"\n",
    "    prev_owner = \"\"\n",
    "    \n",
    "    \n",
    "    for idx_post in range(len(thread)):\n",
    "        post_curr = thread[idx_post]\n",
    "        soup = BeautifulSoup(post_curr[\"text\"], 'html.parser')\n",
    "        #systemsoup = BeautifulSoup(system_post[\"text\"], 'html.parser')\n",
    "        cleantext = clean_html_text(soup)\n",
    "        #system_cleantext = clean_html_text(systemsoup)\n",
    "        \n",
    "        if post_curr[\"role\"] == \"user\":\n",
    "            if prev_owner == \"user\":\n",
    "                conversations += \"\\n\" + cleantext #post_curr[\"text\"]\n",
    "            elif prev_owner == \"system\":\n",
    "                conversations += \"\\n\" + user_template.format(cleantext) #post_curr[\"text\"]\n",
    "            else:\n",
    "                conversations += \"\\n\" + user_template.format(cleantext) #post_curr[\"text\"]\n",
    "\n",
    "        if post_curr[\"role\"] == \"system\":\n",
    "            if prev_owner == \"system\":\n",
    "                conversations += \"\\n\" + cleantext #post_curr[\"text\"]\n",
    "            elif prev_owner == \"user\":\n",
    "                conversations += \"\\n\" + system_template.format(cleantext)\n",
    "            else:\n",
    "                conversations += \"\\n\" + user_template.format(cleantext)\n",
    "\n",
    "        prev_owner = post_curr[\"role\"]\n",
    "    agg_conversations.append(end_template.format(conversations))\n",
    "\n",
    "# create dataframe\n",
    "test_conv_dataframe = pd.DataFrame(agg_conversations, columns=[\"conversations\"])\n",
    "test_conv_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9329897a-b60f-441a-810b-8c29c17afc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_conv_dataframe.to_csv(\"../data/test-conversations.csv\", sep=\"\\t\", index=None)\n",
    "test_conv_dataframe.to_csv(\"../data/documents_conversations_galaxy_help.csv\", sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "961e351d-9b09-45b8-8184-4dec799a1a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/anup/miniconda3/envs/finetune-dnabert2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-24 08:58:46,792] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import torch\n",
    "from transformers import (LlamaTokenizer, LlamaForCausalLM)\n",
    "\n",
    "model_path = 'openlm-research/open_llama_3b_v2'\n",
    "\n",
    "'''model = LlamaForCausalLM.from_pretrained(\n",
    "    model_path, \n",
    "    load_in_8bit=True,\n",
    "    device_map='auto', \n",
    "    # If passing a string for `device_map`, please choose 'auto', 'balanced', 'balanced_low_0' or 'sequential'.\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1'''\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c609e966-44c3-4f7b-8797-9d93eee1e26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7 7\n",
      "1 15 15\n",
      "2 15 15\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_ins_res_pairs(input_string):\n",
    "    pairs_ins_res = []\n",
    "    size_pairs = []\n",
    "    pattern = \"Below is an instruction that describes a task. Write a response that appropriately completes the request\"\n",
    "    matches = [m.start() for m in re.finditer(pattern, input_string)]\n",
    "    #print(matches, len(input_string))\n",
    "    for i in range(len(matches)-1):\n",
    "        f,n = matches[i], matches[i+1]\n",
    "        if i+1 < len(matches)-1:\n",
    "            extracted_conv = input_string[f:n]\n",
    "        else:\n",
    "            extracted_conv = input_string[matches[i+1]:len(input_string)]\n",
    "        input_ids = tokenizer.encode(extracted_conv, return_tensors=\"pt\")\n",
    "        pairs_ins_res.append(extracted_conv)\n",
    "        size_pairs.append(len(input_ids[0]))\n",
    "    return pairs_ins_res, size_pairs\n",
    "\n",
    "ins_res_dataset = []\n",
    "prs_size_dataset = []\n",
    "for idx, item in test_conv_dataframe.iterrows():\n",
    "    prs, size_prs = extract_ins_res_pairs(item[\"conversations\"])\n",
    "    ins_res_dataset.extend(prs)\n",
    "    prs_size_dataset.extend(size_prs)\n",
    "    print(idx, len(ins_res_dataset), len(prs_size_dataset))\n",
    "    if idx == 2:\n",
    "        break\n",
    "individual_conversations = pd.DataFrame(zip(ins_res_dataset, prs_size_dataset), columns=[\"conversations\", \"tensor_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5180ec96-29f3-42f0-803e-bed74c873cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = individual_conversations[\"tensor_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccb0f9de-57e2-46fe-93e0-26c09a68027c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 659.8, 645.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "len(size), np.mean(size), np.median(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3ff1874-733f-4cb1-819f-b9d765d7b8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversations</th>\n",
       "      <th>tensor_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        conversations  tensor_size\n",
       "0   Below is an instruction that describes a task....         1368\n",
       "1   Below is an instruction that describes a task....          497\n",
       "2   Below is an instruction that describes a task....          917\n",
       "3   Below is an instruction that describes a task....          732\n",
       "4   Below is an instruction that describes a task....          639\n",
       "5   Below is an instruction that describes a task....          103\n",
       "6   Below is an instruction that describes a task....         1027\n",
       "7   Below is an instruction that describes a task....          498\n",
       "8   Below is an instruction that describes a task....          908\n",
       "9   Below is an instruction that describes a task....          868\n",
       "10  Below is an instruction that describes a task....          645\n",
       "11  Below is an instruction that describes a task....          371\n",
       "12  Below is an instruction that describes a task....          679\n",
       "13  Below is an instruction that describes a task....          446\n",
       "14  Below is an instruction that describes a task....          199"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_df = individual_conversations #individual_conversations[individual_conversations[\"tensor_size\"] <= 200]\n",
    "small_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48ab312b-de95-42cd-8150-ebd676dabcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.to_csv(\"../data/small-conversations.csv\", sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c21b2-a21e-4ae5-bae5-541f798c52d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4f3d84-ebbf-4da0-8d8d-2a19ad132d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01b3aa-b450-403e-8d78-40681aac5549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96a8e7-09fa-424e-a168-f8d939f8d3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa68c52-a1c7-4c25-addb-9e64d10d4b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc08706-39ca-419b-90e3-771631b0a325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
