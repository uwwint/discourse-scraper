{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d536c2-457e-417e-adea-e8a65b1e4d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/anup/miniconda3/envs/finetune-dnabert2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-24 14:37:02,699] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model_name = \"NousResearch/Llama-2-7b-chat-hf\"\\ncompute_dtype = getattr(torch, \"float16\")\\n\\nbnb_config = BitsAndBytesConfig(\\n    load_in_4bit=True,\\n    bnb_4bit_use_double_quant=True,\\n    bnb_4bit_quant_type=\"nf4\",\\n    bnb_4bit_compute_dtype=compute_dtype\\n)\\n\\nmodel = AutoModelForCausalLM.from_pretrained(\\n    model_name,\\n    quantization_config=bnb_config,\\n    use_cache=False,\\n    device_map=\"auto\"\\n)'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "'''model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    use_cache=False,\n",
    "    device_map=\"auto\"\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69febd92-896d-4f57-aa1c-730d40a6395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM, PeftModel\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d1b9396-7d79-4a79-9bfb-6157c88528c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.84s/it]\n"
     ]
    }
   ],
   "source": [
    "import deepspeed\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "base_dir = \"llama-linear-layers\"\n",
    "checkpoint_number = \"checkpoint-200\"\n",
    "checkpoint_path = \"{}/{}\".format(base_dir, checkpoint_number)\n",
    "\n",
    "#peft_model = PeftModel.from_pretrained(model, checkpoint_path)\n",
    "\n",
    "# load base LLM model and tokenizer\n",
    "peft_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    checkpoint_path,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "#re_tokenizer = AutoTokenizer.from_pretrained(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f70705d-3161-4c12-b281-0a7089303b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-24 14:42:45,691] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.12.3, git-hash=unknown, git-branch=unknown\n",
      "[2023-11-24 14:42:45,694] [INFO] [logging.py:96:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    #\"kernel_inject\": True,\n",
    "    #\"tensor_parallel\": {\"tp_size\": 4},\n",
    "    \"dtype\": \"fp16\",\n",
    "    #\"enable_cuda_graph\": False\n",
    "}\n",
    "\n",
    "ds_engine = deepspeed.init_inference(peft_model, config=config)\n",
    "deepspeed_peft_model = ds_engine.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f64092f1-f2fa-4173-89c7-415359fe5a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear4bit(\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "              )\n",
       "              (k_proj): Linear4bit(\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "              )\n",
       "              (v_proj): Linear4bit(\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "              )\n",
       "              (o_proj): Linear4bit(\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "              )\n",
       "              (down_proj): Linear4bit(\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=11008, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (base_layer): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "              )\n",
       "              (up_proj): Linear4bit(\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "              )\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(\n",
       "        in_features=4096, out_features=32000, bias=False\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): Linear(in_features=8, out_features=32000, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepspeed_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13500d5f-bd89-4b0d-bb78-e04f78f1d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_tokenizer = AutoTokenizer.from_pretrained(checkpoint_path) #checkpoint_path #model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa8781d2-6af9-4a44-9614-5180102bdfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversations</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] I just set up a fresh galaxy ins...</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Dear everyone!\\nI am currently a...</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Really just a minor nuisance, bu...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] I would like someone to explain ...</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hi everyone,\\nI am running a UMI...</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] In my galaxy.yml I have:\\nuser_a...</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hi,\\nI’d like to remove all line...</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] The history window has frequent ...</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] I want to upload the fastQ data ...</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hello, I’m trying to run stringt...</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] How often do I have to update Ga...</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Dear Galaxy community,\\nI need t...</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hello,\\nI’m trying to follow the...</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hello. I am using bowtie2 for my...</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hi.\\nI am going through the gala...</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hello,\\nI am using the main gala...</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] I am trying to upload a database...</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hello,\\nI am new to Galaxy, foll...</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hi, what is causing the error me...</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hello,\\nI am looking to get a fi...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hi all,\\nI’m running galaxy on a...</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] I would either use Ubuntu or Deb...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] I have used the repeatexplorer2 ...</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hi,\\nI have generated the file u...</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hi, Today i installed the histog...</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] I would like to use the Galaxy/h...</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] I have used  GROMACS - gmx, 2020...</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hello!\\nWhen some job ends with ...</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] I’ve been working on a single ce...</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hello,\\nIt has been a couple day...</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hi. I’m running rnaSPAdes with t...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hi. I was trying to generate tra...</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] When I go to @link http://usegal...</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] I am using galaxy for Trinity as...</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hello,\\nI have been trying to ru...</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hello,\\nI’ve been waiting for &gt;1...</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hello\\nI follow Classification i...</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Dear all, Suppose to have a coll...</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] What is the difference between t...</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] I have issue with Cutadapt. Some...</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hi everyone,\\nI am new to NGS da...</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hi Everyone.\\nI followed the spe...</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Today I can’t even reach the sit...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hi all,\\nI am having trouble wit...</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] I am using a local Galaxy instan...</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] How can I use a config file (yam...</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] For the Maker genome annotation ...</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hello.\\nI’m new in bioinformatic...</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Workflow don’t want to start… [/...</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] On the upper nav, there is an op...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] hello,\\n.\\ni am working with can...</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] I have been trying to create a G...</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] I am trying to follow this trans...</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Hello.  Two questions\\n\\nDoes an...</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>\\n\\n&lt;s&gt;[INST] Good Morning! I hereby inform yo...</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        conversations  tokens\n",
       "0   \\n\\n<s>[INST] I just set up a fresh galaxy ins...     202\n",
       "1   \\n\\n<s>[INST] Dear everyone!\\nI am currently a...     504\n",
       "2   \\n\\n<s>[INST] Really just a minor nuisance, bu...     153\n",
       "3   \\n\\n<s>[INST] I would like someone to explain ...     104\n",
       "4   \\n\\n<s>[INST] Hi everyone,\\nI am running a UMI...     462\n",
       "5   \\n\\n<s>[INST] In my galaxy.yml I have:\\nuser_a...     113\n",
       "6   \\n\\n<s>[INST] Hi,\\nI’d like to remove all line...     134\n",
       "7   \\n\\n<s>[INST] The history window has frequent ...     186\n",
       "8   \\n\\n<s>[INST] I want to upload the fastQ data ...     409\n",
       "9   \\n\\n<s>[INST] Hello, I’m trying to run stringt...     732\n",
       "10  \\n\\n<s>[INST] How often do I have to update Ga...     180\n",
       "11  \\n\\n<s>[INST] Dear Galaxy community,\\nI need t...     429\n",
       "12  \\n\\n<s>[INST] Hello,\\nI’m trying to follow the...    1035\n",
       "13  \\n\\n<s>[INST] Hello. I am using bowtie2 for my...     252\n",
       "14  \\n\\n<s>[INST] Hi.\\nI am going through the gala...     260\n",
       "15  \\n\\n<s>[INST] Hello,\\nI am using the main gala...     443\n",
       "16  \\n\\n<s>[INST] I am trying to upload a database...     894\n",
       "17  \\n\\n<s>[INST] Hello,\\nI am new to Galaxy, foll...     288\n",
       "18  \\n\\n<s>[INST] Hi, what is causing the error me...     445\n",
       "19  \\n\\n<s>[INST] Hello,\\nI am looking to get a fi...     100\n",
       "20  \\n\\n<s>[INST] Hi all,\\nI’m running galaxy on a...     381\n",
       "21  \\n\\n<s>[INST] I would either use Ubuntu or Deb...      41\n",
       "22  \\n\\n<s>[INST] I have used the repeatexplorer2 ...     381\n",
       "23  \\n\\n<s>[INST] Hi,\\nI have generated the file u...     342\n",
       "24  \\n\\n<s>[INST] Hi, Today i installed the histog...     152\n",
       "25  \\n\\n<s>[INST] I would like to use the Galaxy/h...     720\n",
       "26  \\n\\n<s>[INST] I have used  GROMACS - gmx, 2020...    1025\n",
       "27  \\n\\n<s>[INST] Hello!\\nWhen some job ends with ...     455\n",
       "28  \\n\\n<s>[INST] I’ve been working on a single ce...     346\n",
       "29  \\n\\n<s>[INST] Hello,\\nIt has been a couple day...     139\n",
       "30  \\n\\n<s>[INST] Hi. I’m running rnaSPAdes with t...     117\n",
       "31  \\n\\n<s>[INST] Hi. I was trying to generate tra...     291\n",
       "32  \\n\\n<s>[INST] When I go to @link http://usegal...     147\n",
       "33  \\n\\n<s>[INST] I am using galaxy for Trinity as...     307\n",
       "34  \\n\\n<s>[INST] Hello,\\nI have been trying to ru...     147\n",
       "35  \\n\\n<s>[INST] Hello,\\nI’ve been waiting for >1...     381\n",
       "36  \\n\\n<s>[INST] Hello\\nI follow Classification i...     148\n",
       "37  \\n\\n<s>[INST] Dear all, Suppose to have a coll...     222\n",
       "38  \\n\\n<s>[INST] What is the difference between t...     265\n",
       "39  \\n\\n<s>[INST] I have issue with Cutadapt. Some...     299\n",
       "40  \\n\\n<s>[INST] Hi everyone,\\nI am new to NGS da...     336\n",
       "41  \\n\\n<s>[INST] Hi Everyone.\\nI followed the spe...     323\n",
       "42  \\n\\n<s>[INST] Today I can’t even reach the sit...      83\n",
       "43  \\n\\n<s>[INST] Hi all,\\nI am having trouble wit...     293\n",
       "44  \\n\\n<s>[INST] I am using a local Galaxy instan...     450\n",
       "45  \\n\\n<s>[INST] How can I use a config file (yam...     422\n",
       "46  \\n\\n<s>[INST] For the Maker genome annotation ...     608\n",
       "47  \\n\\n<s>[INST] Hello.\\nI’m new in bioinformatic...     127\n",
       "48  \\n\\n<s>[INST] Workflow don’t want to start… [/...     199\n",
       "49  \\n\\n<s>[INST] On the upper nav, there is an op...      83\n",
       "50  \\n\\n<s>[INST] hello,\\n.\\ni am working with can...     214\n",
       "51  \\n\\n<s>[INST] I have been trying to create a G...     175\n",
       "52  \\n\\n<s>[INST] I am trying to follow this trans...     250\n",
       "53  \\n\\n<s>[INST] Hello.  Two questions\\n\\nDoes an...     394\n",
       "54  \\n\\n<s>[INST] Good Morning! I hereby inform yo...     211"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "eval_conv = pd.read_csv(\"../data/eval_dataset.csv\", sep=\"\\t\")\n",
    "eval_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "062548b9-2e57-4a96-a58a-a5e0bb8c8898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding prompt number 1...\n",
      "generating response number 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/anup/miniconda3/envs/finetune-dnabert2/lib/python3.9/site-packages/transformers/generation/utils.py:1259: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: \n",
      "\n",
      "I just set up a fresh galaxy installation, following the instructions on: @link https://galaxyproject.org/admin/get-galaxy/ . But once I try to install a tool I get the following error:\n",
      "Error cloning repository: [Errno 2] No such file or directory: ‘hg’: ‘hg’\n",
      "It seems to always be the same error with every tool. Can someone here help me out?\n",
      "EDIT: Found it. Seems I needed to install mercurial. But it seems this is never mentioned in the installation docs?\n",
      "\n",
      "Ground truth answer: \n",
      "\n",
      "I have added a note to our toolshed installation tutorial that should clarify this. @link https://galaxyproject.org/admin/tools/add-tool-from-toolshed-tutorial/#connect-your-galaxy-to-a-tool-shed\n",
      "Thanks for bringing it up!\n",
      "\n",
      "Generated answer: \n",
      "\n",
      "Welcome, @user\n",
      "The problem with cloning repository is due to disk space usage on your server. Allowing your server to run out of space can cause the process to fail.\n",
      "Galaxy can run out of space for temporary work items while the server is waiting for a job queue to run.\n",
      "The issue may be running into this specific resource limit on your server: @link https://galaxyproject.org/admin/tools/tool_limits.html\n",
      "These limits can vary depending on the version you are using, but generally, the recommended limits are:\n",
      "Memory\n",
      "Half the amount of storage (100G).\n",
      "Cores\n",
      "Six to ten for a moderate use case.\n",
      "This link to a similar topic: Help for administrators (@link https://galaxyproject.org/admin/help) details what else could be done. The resources in the link may be more than your require, so use the reference as a guide.\n",
      "As far as installing Mercurial goes, this should have been done first so you can use that tool in Galaxy to version your indexes. The installation may have been missed. It was discussed in your original post as one part of a larger question, but you never actually\n",
      "\n",
      "====================\n",
      "encoding prompt number 2...\n",
      "generating response number 2 ...\n",
      "Instruction: \n",
      "\n",
      "Dear everyone!\n",
      "I am currently analysing the output of a PE sequencing of 96 samples. I have uploaded the reads and included them into a list to use the tools more efficiently. I am running a workflow using snippy, snippy core, Clustal and so. My problem is that 4/96 snippy jobs failed due to memory allocation problems and that interrupted the whole workflow. Even if I delete the failed runs, the output list is marked in red and cant resume the workflow.\n",
      "My question is: Is there a way for me to run the failed snippy jobs and include the output in the list of the successful ones in order to continue with my workflow?\n",
      "I have thought of downloading the successful runs output, running the failed ones again, download these outputs and then after re uploading everything again make a new list but my problem is that the snippy output and the bam files are 54Gb each, way too heavy for me to do.\n",
      "I really appreciate your assistance on this :slight_smile:\n",
      "\n",
      "Ground truth answer: \n",
      "\n",
      "Hi @user\n",
      "@quote\n",
      "My question is: Is there a way for me to run the failed snippy jobs and include the output in the list of the successful ones in order to continue with my workflow?\n",
      "There are two primary solutions for this situation:\n",
      "\n",
      "\n",
      "Instead of deleting failed jobs, rerun instead. The bottom of the tool form will have an extra option to resume dependencies in a way that replaces the original failed datasets.\n",
      "\n",
      "\n",
      "Remove failures during the original workflow run. @link https://training.galaxyproject.org/training-material/topics/galaxy-interface/tutorials/collections/tutorial.html#tools-that-manipulate-elements-within-a-collection\n",
      "\n",
      "\n",
      "More workflow and collection help is here, including examples of programmatically controlled workflow execution.\n",
      "\n",
      "\n",
      "\n",
      "Galaxy Training Network (@link https://training.galaxyproject.org/training-material/topics/galaxy-interface/)\n",
      "\n",
      "\n",
      "Galaxy Training: Using Galaxy and Managing your Data (@link https://training.galaxyproject.org/training-material/topics/galaxy-interface/)\n",
      "A collection of microtutorials explaining various feature...\n",
      "\n",
      "Generated answer: \n",
      "\n",
      "Hi @user, I hope my answers help!\n",
      "The workflow is using the old Snippy2 version, not the latest Snippy, and also it is not the latest cluster’s configuration.\n",
      "First, if you cannot run the latest version, you can use the version you already have.\n",
      "But, in general, it is better to start from the latest version when designing a custom workflow that includes tools that don’t exist in the latest version: it allows to keep the workflow updating on your side.\n",
      "If you still want to use Snippy2, if you are using a HPC cluster, ask for the administrative help, for instance, at your HPC center or at the local IT department, to try to get a cluster’s quota update.\n",
      "To solve your memory problem, you can check if there isn’t any available memory in your cluster for a longer computation (more than two hours, for instance). Some cluster managers could offer you this possibility: ask for it.\n",
      "Hope this helps!\n",
      "Regards,\n",
      "Yeah, if it is not possible to update the cluster, you can download the outputs and then restart your computation. There is already a topic about this, if you type\n",
      "\n",
      "====================\n",
      "encoding prompt number 3...\n",
      "generating response number 3 ...\n",
      "Instruction: \n",
      "\n",
      "Really just a minor nuisance, but if you use @link http://usegalaxy.org in a post, it gets recognized as a hyperlink target, but the same doesn’t work for usegalaxy.eu or usegalaxy.org.au (presumably because .eu and .au are not recognized as top-level domains?). It would just be convenient if that could be changed.\n",
      "\n",
      "Ground truth answer: \n",
      "\n",
      "To my surprise there is actually settings for this in discourse (discourse is great!). I added the two domains there to the allowlist. Test:\n",
      "@link http://usegalaxy.eu\n",
      "@link http://usegalaxy.org.au\n",
      "\n",
      "Generated answer: \n",
      "\n",
      "The Galaxy community is very aggressive about removing links to unregistered galaxy URLs wherever it might be possible. The best practice is to register your Galaxy instance at the Registered Galaxy Instances section of the Galaxy website.  Most Galaxy hosting providers will give you access to a private area of their server for doing this.\n",
      "The link form and link content are different:\n",
      "Any string that looks like a URL can be used in a posting. The link form is a clickable link (“link” in the tool panel), and will open a page in a new tab if it is clicked on. The link content is simply a link that contains the URL, plus some other information that the content can include. The link can be anything that a URL can be, including URLs in other posts.\n",
      "\n",
      "\n",
      "Related information is found on this page:\n",
      "@quote “Register Your Galaxy Server or Publish Work to the Cloud\n",
      "Galaxy is a popular open science web application/Platform that hosts resources, tools, and services supporting life science research: genomics, transcriptomics, proteomics, metabolomics and computational biology.\n",
      "The Galaxy website helps you find and discover Galaxy Resources or\n",
      "\n",
      "====================\n",
      "encoding prompt number 4...\n",
      "generating response number 4 ...\n",
      "Instruction: \n",
      "\n",
      "I would like someone to explain to me what is unassigned ambiguity.\n",
      "thanks for advance\n",
      "\n",
      "Ground truth answer: \n",
      "\n",
      "Hi @user\n",
      "consider checking the manual by clicking at Subread link available in paragraph under Execute button:\n",
      "Unassigned Ambiguity: alignments that overlap two or more features (feature-level sum-\n",
      "marization) or meta-features (meta-feature-level summarization).\n",
      "Kind regards,\n",
      "Igor\n",
      "\n",
      "Generated answer: \n",
      "\n",
      "Hello @user\n",
      "you should consider sharing some details about the history files you are interested in with more context. You could then perhaps ask a new question with more exact details and a clear goal.\n",
      "The term, unassigned ambiguity, makes me suspect that it may be related to feature counting. In general, feature counting is used when the coverage is high and quality is very good but you would like to increase the number of features you have to give them more meaning. There are many ways to achieve this. One way is to define new classes to make some of the features more meaning, by using feature counting.\n",
      "This is the result for which unassigned ambiguity comes into play. You define all the features that belong to the current class and the feature counting function returns a count. You would use that result to recalculate feature coverage.\n",
      "The tool I would suggest is the following.\n",
      "@link https://usegalaxy.eu/root?query=feature+count&display=search\n",
      "At the bottom of the page, there is a gear icon. When you click on it, you can select Advanced options.\n",
      "Here you can include other variables in the analysis. For example, you would include the taxa assigned to a certain\n",
      "\n",
      "====================\n",
      "encoding prompt number 5...\n",
      "generating response number 5 ...\n",
      "Instruction: \n",
      "\n",
      "Hi everyone,\n",
      "I am running a UMI-tools extract command that works on HPC:\n",
      "(example of nextflow command)\n",
      "umi_tools extract --extract-method=regex \n",
      "–bc-pattern=\".+(?P<discard_1>AACTGTAGGCACCATCAAT){s<=2}(?P<umi_1>.{12})$\" \n",
      "-I ${sample_name}_trimmed.fastq \n",
      "-S ${sample_name}_umi_cleaned.fastq > ${sample_name}_umi_tools.log\n",
      "but it does not run properly on Galaxy\n",
      "I need to specify the following regex so UMI-tools detect the UMI at the end:\n",
      ".+(?P<discard_1>AACTGTAGGCACCATCAAT){s<=2}(?P<umi_1>.{12})$\n",
      "However, when I run it on GA, the + and the $ seem to be dropped:\n",
      "In the log, the pattern comes up as: .(?P<discard_1>AACTGTAGGCACCATCAAT){s<=2}(?P<umi_1>.{12})\n",
      "And although UMI runs it fails to correctly detect the adapter and UMI at the end of the read. I end up with a few hundred reads 1-2 bp long instead of several million reads with their proper UMI extracted.\n",
      "I also tried to use backslashes :.\\+(?P<discard_1>AACTGTAGGCACCATCAAT){s<=2}(?P<umi_1>.{12})\\$\n",
      "and an asterisk\n",
      "`.*(?P<discard_1>AACTGTAGGCACCATCAAT){s<=2}(?P<umi_1>.{12})``\n",
      "But both failed\n",
      "Thanks for your help\n",
      "\n",
      "Ground truth answer: \n",
      "\n",
      "Hi @user,\n",
      "I opened a PR (@link https://github.com/galaxyproject/tools-iuc/pull/4180) in order to fix it.\n",
      "Regards\n",
      "\n",
      "Generated answer: \n",
      "\n",
      "The issue is in the regular expression. It was reported as a bug. Please include the latest update in this post or maybe the old workflow can be opened again to add it: Implement Regular Expressions in Galaxy: UMI-Tools -#29 by bcorbyn (@link https://github.com/galaxyproject/umi-tools/issues/29)\n",
      "The regular expression has been removed/fixed and should again now work.\n",
      "In summary the regular expression should be modified to: .{12}(?P<umi_match>.{12})\n",
      "Thanks for reporting the problem and our apologies for the trouble! The community will review it soon.\n",
      "A temporary solution is to include a literal dot “.” at the start of the string. But this isn’t ideal since this would include the base name and thus prevent multiple reads from being extracted properly. But it is working with the current version of the tool.\n",
      "The regular expression could also be modified as you suggested, by adding a backslash and an asterisk to the beginning, but this also has different results. To clarify, the Galactic regular expressions can use some special symbols in the string, but those are considered different than the standard symbols\n",
      "\n",
      "====================\n",
      "encoding prompt number 6...\n",
      "generating response number 6 ...\n",
      "Instruction: \n",
      "\n",
      "In my galaxy.yml I have:\n",
      "user_activation_on: true\n",
      "activation_grace_period: 0\n",
      "\n",
      "If you are not logged in you are still able to see the tool menu. How can I configure galaxy so only logged in users can see the tools?\n",
      "EDIT:\n",
      "I can also upload when not logged in\n",
      "Thanks in advanced\n",
      "\n",
      "Ground truth answer: \n",
      "\n",
      "# Force everyone to log in (disable anonymous access).\n",
      "#require_login: false\n",
      "\n",
      "Generated answer: \n",
      "\n",
      "Hi @user,\n",
      "this would be the recommended configuration:\n",
      "\n",
      "from the Admin > Tools menu, go to Edit, then change the User display to display for logged-in users\n",
      "\n",
      "@quote\n",
      "user::display_for_unauthenticated_users_option: loggedin # hide tools from unregistered users (this is the default)\n",
      "user::display_for_unauthenticated_users_option: all # allow tools to be seen by unregistered users only\n",
      "user::display_for_logging_out_users_option: none # allow tools to stay displayed when current_user logs out\n",
      "\n",
      "This will hide unregistered users for any tool that you set with the datatypes you don’t want to be shown to them anyway (@quote)\n",
      "user::display_for_unauthenticated_users_option: none, and they will be able to upload/edit only in the tools you specify, not even just for browsing their contents.\n",
      "#user::display_for_previous_users_option: never # prevent logged-out users coming back to a “frozen” data unless explicitly given the current user’s email address or name (@quote)\n",
      "\n",
      "Please review this\n",
      "\n",
      "====================\n",
      "Finished generation in 284.3469796180725 seconds\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "original_instructions = []\n",
    "ground_truth_answer = []\n",
    "extracted_answers = []\n",
    "\n",
    "start_marker = '<s>[INST]'\n",
    "end_marker = '[/INST]'\n",
    "end_tag = \"</s>\"\n",
    "\n",
    "s_time = time.time()\n",
    "\n",
    "for ri, row in eval_conv.iterrows():\n",
    "    entire_conv = row[\"conversations\"]\n",
    "    start_index = entire_conv.find(start_marker)\n",
    "    end_index = entire_conv.find(end_marker)\n",
    "    instruction = entire_conv[start_index + len(start_marker):end_index].strip()\n",
    "    prompt = entire_conv[start_index:end_index + len(end_marker)].strip()\n",
    "    original_answer = entire_conv[end_index + len(end_marker): len(entire_conv) - len(end_tag) - 1].strip()\n",
    "    original_instructions.append(instruction)\n",
    "    ground_truth_answer.append(original_answer)\n",
    "    print(\"encoding prompt number {}...\".format(ri+1))\n",
    "    input_ids = restored_tokenizer.encode(prompt, return_tensors=\"pt\").to('cuda')\n",
    "    print(\"generating response number {} ...\".format(ri+1))\n",
    "    outputs = deepspeed_peft_model.generate(input_ids=input_ids, \n",
    "        max_new_tokens=256,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    pred = restored_tokenizer.decode(outputs[0])\n",
    "    extracted_pred = pred[pred.find(end_marker) + len(end_marker): len(pred)].strip()\n",
    "    predictions.append(pred)\n",
    "    extracted_answers.append(extracted_pred)\n",
    "    print(\"Instruction: \\n\")\n",
    "    print(instruction)\n",
    "    print()\n",
    "    print(\"Ground truth answer: \\n\")\n",
    "    print(original_answer)\n",
    "    print()\n",
    "    print(\"Generated answer: \\n\")\n",
    "    print(extracted_pred)\n",
    "    print()\n",
    "    print(\"====================\")\n",
    "    if ri == 5:\n",
    "        break\n",
    "\n",
    "#\"{}/{}\".format(base_dir, checkpoint_number)\n",
    "output_file_name = \"generated_answers_peft_{}_{}\".format(base_dir, checkpoint_number)\n",
    "\n",
    "pred_dataframe = pd.DataFrame(zip(original_instructions, ground_truth_answer, extracted_answers, predictions), columns=[\"Instructions\", \"Ground truth answers\", \"Predicted answers\", \"Full generated answers\"])\n",
    "\n",
    "pred_dataframe.to_csv(\"../data/{}.csv\".format(output_file_name), sep=\"\\t\", index=None)\n",
    "\n",
    "e_time = time.time()\n",
    "\n",
    "print(\"Finished generation in {} seconds\".format(e_time - s_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10fc458-25ff-4e67-95a0-21efbdda5749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
