{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acc0c4e4-a007-4d83-b543-15d5b2d7f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import torch\n",
    "from transformers import (LlamaTokenizer, LlamaForCausalLM)\n",
    "\n",
    "model_path = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e593754-a585-47c8-9065-be3a1a1ae745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "465acb07-da84-433b-a4fe-dbc24f30fb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/centos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/centos/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "## Clean text\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import contractions\n",
    "import ftfy\n",
    "\n",
    "\n",
    "## Text preprocessing for fine tuning\n",
    "## https://www.linkedin.com/pulse/pre-processing-text-data-gpt-models-techniques-best-practices-tilix/\n",
    "## TODO: https://ftfy.readthedocs.io/en/latest/\n",
    "## TODO: Read this: https://arxiv.org/abs/2212.10496\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    clean_text = text.translate(translator)\n",
    "    return clean_text\n",
    "\n",
    "def lowercase_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "def wikitext_detokenizer(string):\n",
    "    # https://github.com/kingoflolz/mesh-transformer-jax/blob/master/create_finetune_tfrecords.py\n",
    "    # contractions\n",
    "    string = string.replace(\"s '\", \"s'\")\n",
    "    string = re.sub(r\"/' [0-9]/\", r\"/'[0-9]/\", string)\n",
    "    # number separators\n",
    "    string = string.replace(\" @-@ \", \"-\")\n",
    "    string = string.replace(\" @,@ \", \",\")\n",
    "    string = string.replace(\" @.@ \", \".\")\n",
    "    # punctuation\n",
    "    string = string.replace(\" : \", \": \")\n",
    "    string = string.replace(\" ; \", \"; \")\n",
    "    string = string.replace(\" . \", \". \")\n",
    "    string = string.replace(\" ! \", \"! \")\n",
    "    string = string.replace(\" ? \", \"? \")\n",
    "    string = string.replace(\" , \", \", \")\n",
    "    # double brackets\n",
    "    string = re.sub(r\"\\(\\s*([^\\)]*?)\\s*\\)\", r\"(\\1)\", string)\n",
    "    string = re.sub(r\"\\[\\s*([^\\]]*?)\\s*\\]\", r\"[\\1]\", string)\n",
    "    string = re.sub(r\"{\\s*([^}]*?)\\s*}\", r\"{\\1}\", string)\n",
    "    string = re.sub(r\"\\\"\\s*([^\\\"]*?)\\s*\\\"\", r'\"\\1\"', string)\n",
    "    string = re.sub(r\"'\\s*([^']*?)\\s*'\", r\"'\\1'\", string)\n",
    "    # miscellaneous\n",
    "    string = string.replace(\"= = = =\", \"====\")\n",
    "    string = string.replace(\"= = =\", \"===\")\n",
    "    string = string.replace(\"= =\", \"==\")\n",
    "    string = string.replace(\" \" + chr(176) + \" \", chr(176))\n",
    "    string = string.replace(\" \\n\", \"\\n\")\n",
    "    string = string.replace(\"\\n \", \"\\n\")\n",
    "    string = string.replace(\" N \", \" 1 \")\n",
    "    string = string.replace(\" 's\", \"'s\")\n",
    "\n",
    "    return string\n",
    "\n",
    "def clean_html_text(soup: BeautifulSoup):\n",
    "    # Process quote aside tags\n",
    "    rgx = \"<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\"\n",
    "    cleanr = re.compile(rgx)\n",
    "    cleantext = re.sub(cleanr, '', str(soup))\n",
    "\n",
    "    cleantext = re.sub(r'Screen.+KB', '', cleantext)\n",
    "    cleantext = re.sub(r'[0-9].+KB', '', cleantext)\n",
    "    cleantext = re.sub(r'Kind.+[a-z0-9]', '', cleantext)\n",
    "    cleantext = re.sub(r'Dear @.+[a-z0-9]', '', cleantext)\n",
    "    cleantext = re.sub(r'Hi @.+[a-z0-9]', '', cleantext)\n",
    "    cleantext = re.sub(r'Hello @.+[a-z0-9]', '', cleantext)\n",
    "    cleantext = re.sub(r'Cheers', '', cleantext)\n",
    "    cleantext = re.sub(r'Best .+[a-z0-9]', '', cleantext)\n",
    "    cleantext = wikitext_detokenizer(cleantext)\n",
    "    cleantext = lowercase_text(cleantext)\n",
    "    cleantext = ftfy.fix_text(cleantext)\n",
    "    tagged_sentence = nltk.tag.pos_tag(cleantext.split())\n",
    "    cleantext = [word for word, tag in tagged_sentence if tag != 'NNP' and tag != 'NNPS']\n",
    "    cleantext = \" \".join(cleantext)\n",
    "    # fix contractions\n",
    "    cleantext = contractions.fix(cleantext)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5240d8e0-0b92-4d4e-b9f2-cb0944b49a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_174402/658830169.py:36: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  systemsoup = BeautifulSoup(system_post[\"text\"], 'html.parser')\n",
      "/tmp/ipykernel_174402/658830169.py:35: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  usersoup = BeautifulSoup(user_post[\"text\"], 'html.parser')\n",
      "/scratch/users/anup/miniconda3/envs/finetune-dnabert2/lib/python3.9/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversations</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1256 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          conversations  tokens\n",
       "0     Act like Bioinformatician who uses Galaxy plat...     462\n",
       "1     Act like Bioinformatician who uses Galaxy plat...     888\n",
       "2     Act like Bioinformatician who uses Galaxy plat...     917\n",
       "3     Act like Bioinformatician who uses Galaxy plat...     143\n",
       "4     Act like Bioinformatician who uses Galaxy plat...     302\n",
       "...                                                 ...     ...\n",
       "1251  Act like Bioinformatician who uses Galaxy plat...     232\n",
       "1252  Act like Bioinformatician who uses Galaxy plat...     187\n",
       "1253  Act like Bioinformatician who uses Galaxy plat...     262\n",
       "1254  Act like Bioinformatician who uses Galaxy plat...     383\n",
       "1255  Act like Bioinformatician who uses Galaxy plat...     234\n",
       "\n",
       "[1256 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "file_name = \"data_galaxy_q_a.json\"\n",
    "output_file_name = \"conversations-galaxy-q-a.csv\"\n",
    "\n",
    "with open(\"../out/\" + file_name) as fout:\n",
    "    raw_data = json.load(fout)\n",
    "\n",
    "\"\"\"\n",
    "<s>[INST] <<SYS>>\\n \\n\n",
    "<</SYS>>\\n\\n {} [/INST] {} </s>\n",
    "<s>[INST] {user_message_2} [/INST]\n",
    "\"\"\"\n",
    "\n",
    "#system_message = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "system_message = \"Act like Bioinformatician who uses Galaxy platform for biological data analysis. Understand the following instruction and prepare a suitable response.\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "[INST] <<SYS>> \\n {} \\n <</SYS>> \\n\\n {} [/INST] {}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template_no_sys = \"\"\"\n",
    "[INST] {} [/INST] {}\n",
    "\"\"\"\n",
    "\n",
    "agg_conversations = []\n",
    "size_conversations = []\n",
    "\n",
    "for idx_thread in range(len(raw_data)):\n",
    "    user_post = raw_data[idx_thread][0]\n",
    "    system_post = raw_data[idx_thread][1]\n",
    "    if user_post[\"role\"] == \"user\" and system_post[\"role\"] == \"system\":\n",
    "        \n",
    "        usersoup = BeautifulSoup(user_post[\"text\"], 'html.parser')\n",
    "        systemsoup = BeautifulSoup(system_post[\"text\"], 'html.parser')\n",
    "        user_cleantext = clean_html_text(usersoup)\n",
    "        system_cleantext = clean_html_text(systemsoup)\n",
    "        conversations = system_message + \"\\n\" + prompt_template_no_sys.format(user_cleantext, system_cleantext)\n",
    "        input_ids = tokenizer.encode(conversations, return_tensors=\"pt\")\n",
    "        size_conversations.append(len(input_ids[0]))\n",
    "        agg_conversations.append(conversations)\n",
    "\n",
    "# create dataframe\n",
    "test_conv_dataframe = pd.DataFrame(zip(agg_conversations, size_conversations), columns=[\"conversations\", \"tokens\"])\n",
    "test_conv_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b662912d-a8f1-429b-8850-69e97531cc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1256, 409.3391719745223, 304.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "size = test_conv_dataframe[\"tokens\"]\n",
    "len(size), np.mean(size), np.median(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2e70dd3-6409-46e8-8873-185206362bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversations</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>Act like Bioinformatician who uses Galaxy plat...</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1127 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          conversations  tokens\n",
       "0     Act like Bioinformatician who uses Galaxy plat...     462\n",
       "3     Act like Bioinformatician who uses Galaxy plat...     143\n",
       "4     Act like Bioinformatician who uses Galaxy plat...     302\n",
       "5     Act like Bioinformatician who uses Galaxy plat...     204\n",
       "6     Act like Bioinformatician who uses Galaxy plat...     445\n",
       "...                                                 ...     ...\n",
       "1251  Act like Bioinformatician who uses Galaxy plat...     232\n",
       "1252  Act like Bioinformatician who uses Galaxy plat...     187\n",
       "1253  Act like Bioinformatician who uses Galaxy plat...     262\n",
       "1254  Act like Bioinformatician who uses Galaxy plat...     383\n",
       "1255  Act like Bioinformatician who uses Galaxy plat...     234\n",
       "\n",
       "[1127 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_df = test_conv_dataframe[test_conv_dataframe[\"tokens\"] <= 700]\n",
    "small_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9329897a-b60f-441a-810b-8c29c17afc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.to_csv(\"../data/\" + output_file_name, sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e351d-9b09-45b8-8184-4dec799a1a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c609e966-44c3-4f7b-8797-9d93eee1e26d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c21b2-a21e-4ae5-bae5-541f798c52d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4f3d84-ebbf-4da0-8d8d-2a19ad132d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01b3aa-b450-403e-8d78-40681aac5549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96a8e7-09fa-424e-a168-f8d939f8d3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa68c52-a1c7-4c25-addb-9e64d10d4b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc08706-39ca-419b-90e3-771631b0a325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
