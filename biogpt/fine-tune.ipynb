{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a8f95bd-7224-4a1c-b350-5fab83141e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b063814-eadf-4a17-9c83-ed2418defac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, I have a very basic notebook running in ou...</td>\n",
       "      <td>Cross-referenced post: galaxyproject/admins - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Any ideas yet what is going on with put and ge...</td>\n",
       "      <td>\\n\\n\\n maikenp:\\n\\njupyter\\n\\n\\nHi @maikenp\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The key point being I think the use of the qua...</td>\n",
       "      <td>Ok! Progress  Did you set galaxy_infrastructur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@hxr do you have some advice on what would be ...</td>\n",
       "      <td>Hi @maikenp sorry for the delay, too many thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi, I met an error when I used the Trinity too...</td>\n",
       "      <td>Hi @luweidong\\nTry transcript assembly for a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>hello,\\n.\\ni am working with candida genome pr...</td>\n",
       "      <td>Hi @dina_yamin!\\nYes this is correct. You coul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>I have been trying to create a Galaxy Interact...</td>\n",
       "      <td>Hi @christos-efthymiou,\\nI suggest you write t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>I am trying to follow this transcriptomic tuto...</td>\n",
       "      <td>Hi @Arslan_Tariq,\\nthose files are available o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>Hello.  Two questions\\n\\nDoes anyone know whet...</td>\n",
       "      <td>Hello @bionewbie\\n\\n\\n\\n bionewbie:\\n\\nDoes an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>Good Morning! I hereby inform you that my asse...</td>\n",
       "      <td>@angelo_braga\\nIt is normal for jobs (any tool...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1535 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 source  \\\n",
       "0     Hi, I have a very basic notebook running in ou...   \n",
       "1     Any ideas yet what is going on with put and ge...   \n",
       "2     The key point being I think the use of the qua...   \n",
       "3     @hxr do you have some advice on what would be ...   \n",
       "4     Hi, I met an error when I used the Trinity too...   \n",
       "...                                                 ...   \n",
       "1530  hello,\\n.\\ni am working with candida genome pr...   \n",
       "1531  I have been trying to create a Galaxy Interact...   \n",
       "1532  I am trying to follow this transcriptomic tuto...   \n",
       "1533  Hello.  Two questions\\n\\nDoes anyone know whet...   \n",
       "1534  Good Morning! I hereby inform you that my asse...   \n",
       "\n",
       "                                                 target  \n",
       "0     Cross-referenced post: galaxyproject/admins - ...  \n",
       "1     \\n\\n\\n maikenp:\\n\\njupyter\\n\\n\\nHi @maikenp\\nS...  \n",
       "2     Ok! Progress  Did you set galaxy_infrastructur...  \n",
       "3     Hi @maikenp sorry for the delay, too many thin...  \n",
       "4     Hi @luweidong\\nTry transcript assembly for a s...  \n",
       "...                                                 ...  \n",
       "1530  Hi @dina_yamin!\\nYes this is correct. You coul...  \n",
       "1531  Hi @christos-efthymiou,\\nI suggest you write t...  \n",
       "1532  Hi @Arslan_Tariq,\\nthose files are available o...  \n",
       "1533  Hello @bionewbie\\n\\n\\n\\n bionewbie:\\n\\nDoes an...  \n",
       "1534  @angelo_braga\\nIt is normal for jobs (any tool...  \n",
       "\n",
       "[1535 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../out/data.json\") as fout:\n",
    "    raw_data = json.load(fout)\n",
    "\n",
    "question = []\n",
    "response = []\n",
    "for idx_thread, thread in enumerate(raw_data):\n",
    "    for idx_post in range(int(len(thread) / 2)):\n",
    "        next_posts = thread[idx_post:idx_post+2]\n",
    "        if next_posts[0][\"role\"] == \"user\" and next_posts[1][\"role\"] == \"system\":\n",
    "            question.append(next_posts[0][\"text\"])\n",
    "            response.append(next_posts[1][\"text\"])\n",
    "\n",
    "# create dataframe\n",
    "q_a_dataframe = pd.DataFrame(zip(question, response), columns=[\"source\", \"target\"])\n",
    "q_a_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6325eeaa-1fd9-443c-829b-1bc2427fd8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, I have a very basic notebook running in ou...</td>\n",
       "      <td>Cross-referenced post: galaxyproject/admins - ...</td>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Any ideas yet what is going on with put and ge...</td>\n",
       "      <td>\\n\\n\\n maikenp:\\n\\njupyter\\n\\n\\nHi @maikenp\\nS...</td>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The key point being I think the use of the qua...</td>\n",
       "      <td>Ok! Progress  Did you set galaxy_infrastructur...</td>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@hxr do you have some advice on what would be ...</td>\n",
       "      <td>Hi @maikenp sorry for the delay, too many thin...</td>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi, I met an error when I used the Trinity too...</td>\n",
       "      <td>Hi @luweidong\\nTry transcript assembly for a s...</td>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>hello,\\n.\\ni am working with candida genome pr...</td>\n",
       "      <td>Hi @dina_yamin!\\nYes this is correct. You coul...</td>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>I have been trying to create a Galaxy Interact...</td>\n",
       "      <td>Hi @christos-efthymiou,\\nI suggest you write t...</td>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>I am trying to follow this transcriptomic tuto...</td>\n",
       "      <td>Hi @Arslan_Tariq,\\nthose files are available o...</td>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>Hello.  Two questions\\n\\nDoes anyone know whet...</td>\n",
       "      <td>Hello @bionewbie\\n\\n\\n\\n bionewbie:\\n\\nDoes an...</td>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>Good Morning! I hereby inform you that my asse...</td>\n",
       "      <td>@angelo_braga\\nIt is normal for jobs (any tool...</td>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1535 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 source  \\\n",
       "0     Hi, I have a very basic notebook running in ou...   \n",
       "1     Any ideas yet what is going on with put and ge...   \n",
       "2     The key point being I think the use of the qua...   \n",
       "3     @hxr do you have some advice on what would be ...   \n",
       "4     Hi, I met an error when I used the Trinity too...   \n",
       "...                                                 ...   \n",
       "1530  hello,\\n.\\ni am working with candida genome pr...   \n",
       "1531  I have been trying to create a Galaxy Interact...   \n",
       "1532  I am trying to follow this transcriptomic tuto...   \n",
       "1533  Hello.  Two questions\\n\\nDoes anyone know whet...   \n",
       "1534  Good Morning! I hereby inform you that my asse...   \n",
       "\n",
       "                                                 target  \\\n",
       "0     Cross-referenced post: galaxyproject/admins - ...   \n",
       "1     \\n\\n\\n maikenp:\\n\\njupyter\\n\\n\\nHi @maikenp\\nS...   \n",
       "2     Ok! Progress  Did you set galaxy_infrastructur...   \n",
       "3     Hi @maikenp sorry for the delay, too many thin...   \n",
       "4     Hi @luweidong\\nTry transcript assembly for a s...   \n",
       "...                                                 ...   \n",
       "1530  Hi @dina_yamin!\\nYes this is correct. You coul...   \n",
       "1531  Hi @christos-efthymiou,\\nI suggest you write t...   \n",
       "1532  Hi @Arslan_Tariq,\\nthose files are available o...   \n",
       "1533  Hello @bionewbie\\n\\n\\n\\n bionewbie:\\n\\nDoes an...   \n",
       "1534  @angelo_braga\\nIt is normal for jobs (any tool...   \n",
       "\n",
       "                                                 prompt  \n",
       "0      Below is an instruction that describes a task...  \n",
       "1      Below is an instruction that describes a task...  \n",
       "2      Below is an instruction that describes a task...  \n",
       "3      Below is an instruction that describes a task...  \n",
       "4      Below is an instruction that describes a task...  \n",
       "...                                                 ...  \n",
       "1530   Below is an instruction that describes a task...  \n",
       "1531   Below is an instruction that describes a task...  \n",
       "1532   Below is an instruction that describes a task...  \n",
       "1533   Below is an instruction that describes a task...  \n",
       "1534   Below is an instruction that describes a task...  \n",
       "\n",
       "[1535 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\" Below is an instruction that describes a task. Write a response that appropriately completes the request: \\n;\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response: \\n\"\"\"\n",
    "\n",
    "q_a_dataframe['prompt'] = q_a_dataframe[\"source\"].apply(lambda x: template.format(x))\n",
    "q_a_dataframe.to_csv(\"qa_data/q_a_dataframe.csv\", sep=\",\", index=None)\n",
    "q_a_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79fb4441-7bce-4a2d-b405-10efc98d2ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "      <td>Cross-referenced post: galaxyproject/admins - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "      <td>\\n\\n\\n maikenp:\\n\\njupyter\\n\\n\\nHi @maikenp\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "      <td>Ok! Progress  Did you set galaxy_infrastructur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "      <td>Hi @maikenp sorry for the delay, too many thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "      <td>Hi @luweidong\\nTry transcript assembly for a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "      <td>Hi @dina_yamin!\\nYes this is correct. You coul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "      <td>Hi @christos-efthymiou,\\nI suggest you write t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "      <td>Hi @Arslan_Tariq,\\nthose files are available o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "      <td>Hello @bionewbie\\n\\n\\n\\n bionewbie:\\n\\nDoes an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "      <td>@angelo_braga\\nIt is normal for jobs (any tool...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1535 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt  \\\n",
       "0      Below is an instruction that describes a task...   \n",
       "1      Below is an instruction that describes a task...   \n",
       "2      Below is an instruction that describes a task...   \n",
       "3      Below is an instruction that describes a task...   \n",
       "4      Below is an instruction that describes a task...   \n",
       "...                                                 ...   \n",
       "1530   Below is an instruction that describes a task...   \n",
       "1531   Below is an instruction that describes a task...   \n",
       "1532   Below is an instruction that describes a task...   \n",
       "1533   Below is an instruction that describes a task...   \n",
       "1534   Below is an instruction that describes a task...   \n",
       "\n",
       "                                                 target  \n",
       "0     Cross-referenced post: galaxyproject/admins - ...  \n",
       "1     \\n\\n\\n maikenp:\\n\\njupyter\\n\\n\\nHi @maikenp\\nS...  \n",
       "2     Ok! Progress  Did you set galaxy_infrastructur...  \n",
       "3     Hi @maikenp sorry for the delay, too many thin...  \n",
       "4     Hi @luweidong\\nTry transcript assembly for a s...  \n",
       "...                                                 ...  \n",
       "1530  Hi @dina_yamin!\\nYes this is correct. You coul...  \n",
       "1531  Hi @christos-efthymiou,\\nI suggest you write t...  \n",
       "1532  Hi @Arslan_Tariq,\\nthose files are available o...  \n",
       "1533  Hello @bionewbie\\n\\n\\n\\n bionewbie:\\n\\nDoes an...  \n",
       "1534  @angelo_braga\\nIt is normal for jobs (any tool...  \n",
       "\n",
       "[1535 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_a_dataframe = q_a_dataframe[['prompt', 'target']]\n",
    "q_a_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f09c50a8-74b8-41fc-ad6a-e8250653728c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>Below is an instruction that describes a task...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1535 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0      Below is an instruction that describes a task...\n",
       "1      Below is an instruction that describes a task...\n",
       "2      Below is an instruction that describes a task...\n",
       "3      Below is an instruction that describes a task...\n",
       "4      Below is an instruction that describes a task...\n",
       "...                                                 ...\n",
       "1530   Below is an instruction that describes a task...\n",
       "1531   Below is an instruction that describes a task...\n",
       "1532   Below is an instruction that describes a task...\n",
       "1533   Below is an instruction that describes a task...\n",
       "1534   Below is an instruction that describes a task...\n",
       "\n",
       "[1535 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, (1535, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_a_dataframe['text'] = q_a_dataframe[\"prompt\"] + q_a_dataframe[\"target\"] + \"\\n ###END\"\n",
    "q_a_dataframe.drop(columns=['prompt', 'target'], inplace=True)\n",
    "q_a_dataframe.to_csv(\"qa_data/q_a_dataframe_text.csv\", sep=\",\", index=None)\n",
    "display(q_a_dataframe), q_a_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c691a856-202c-4937-9ca2-5dc6088aec82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/anup/miniconda3/envs/finetune-dnabert2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(q_a_dataframe).train_test_split(test_size=0.05, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caad485f-1d7c-4519-8b26-356b7ba99b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.modules of BioGptForCausalLM(\n",
      "  (biogpt): BioGptModel(\n",
      "    (embed_tokens): Embedding(42384, 1024, padding_idx=1)\n",
      "    (embed_positions): BioGptLearnedPositionalEmbedding(1026, 1024)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x BioGptDecoderLayer(\n",
      "        (self_attn): BioGptAttention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_fn): GELUActivation()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (output_projection): Linear(in_features=1024, out_features=42384, bias=False)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BioGptTokenizer, BioGptForCausalLM, set_seed\n",
    "import re\n",
    "import sys\n",
    "\n",
    "model_path = \"microsoft/biogpt\"\n",
    "\n",
    "tokenizer = BioGptTokenizer.from_pretrained(model_path)\n",
    "model = BioGptForCausalLM.from_pretrained(model_path, torch_dtype=torch.float32)\n",
    "\n",
    "model_modules = str(model.modules)\n",
    "print(model_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e593754-a585-47c8-9065-be3a1a1ae745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 786,432 || all params: 347,549,696 || trainable%: 0.22627900672944337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1458/1458 [00:09<00:00, 153.95 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 77/77 [00:00<00:00, 140.37 examples/s]\n",
      "/scratch/users/anup/miniconda3/envs/finetune-dnabert2/lib/python3.9/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1820' max='1820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1820/1820 2:36:54, Epoch 19/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.290600</td>\n",
       "      <td>5.078582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.206500</td>\n",
       "      <td>4.969420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.089000</td>\n",
       "      <td>4.853086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.921400</td>\n",
       "      <td>4.736055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.859800</td>\n",
       "      <td>4.622971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.751400</td>\n",
       "      <td>4.522762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.656100</td>\n",
       "      <td>4.439159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.521600</td>\n",
       "      <td>4.366831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.500300</td>\n",
       "      <td>4.308059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.438800</td>\n",
       "      <td>4.257466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.386600</td>\n",
       "      <td>4.212727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.296800</td>\n",
       "      <td>4.173714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.305500</td>\n",
       "      <td>4.140417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.270800</td>\n",
       "      <td>4.112080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.243600</td>\n",
       "      <td>4.087399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>4.177200</td>\n",
       "      <td>4.067388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>4.208300</td>\n",
       "      <td>4.053039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>4.195900</td>\n",
       "      <td>4.042900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>4.185500</td>\n",
       "      <td>4.036810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>4.144300</td>\n",
       "      <td>4.034923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1820, training_loss=4.533236593728537, metrics={'train_runtime': 9417.105, 'train_samples_per_second': 3.096, 'train_steps_per_second': 0.193, 'total_flos': 1.1468621524893696e+16, 'train_loss': 4.533236593728537, 'epoch': 19.95})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "import torch\n",
    "from transformers.trainer_callback import TrainerCallback\n",
    "import os\n",
    "import sys\n",
    "from transformers import BitsAndBytesConfig\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "target_modules = ['q_proj','v_proj']\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules = target_modules,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "base_dir = \"biogpt\"\n",
    "\n",
    "per_device_train_batch_size = 4\n",
    "gradient_accumulation_steps = 4\n",
    "optim = 'adamw_hf'\n",
    "learning_rate = 1e-5\n",
    "max_grad_norm = 0.3\n",
    "warmup_ratio = 0.03\n",
    "lr_scheduler_type = \"linear\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=base_dir,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs = 20.0,\n",
    "    logging_strategy=\"epoch\",\n",
    "    logging_steps=200,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    learning_rate=learning_rate,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    ")\n",
    "    \n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset = dataset['test'],\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=256,\n",
    "    args=training_args,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3ff1874-733f-4cb1-819f-b9d765d7b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine_tuned_model_path = \"saved-model\"\n",
    "#tokenizer.save_pretrained(fine_tuned_model_path)\n",
    "#model.save_pretrained(fine_tuned_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab312b-de95-42cd-8150-ebd676dabcc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d7c21b2-a21e-4ae5-bae5-541f798c52d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re_tokenizer = BioGptTokenizer.from_pretrained(\"biogpt/checkpoint-273\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c4f3d84-ebbf-4da0-8d8d-2a19ad132d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re_model = BioGptForCausalLM.from_pretrained(\"biogpt/checkpoint-273\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed01b3aa-b450-403e-8d78-40681aac5549",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 22\u001b[0m\n\u001b[1;32m     13\u001b[0m   prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m Below is an instruction that describes a task. Write a response that appropriately completes the request: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m;\u001b[39m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m  ### Instruction:\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;124m  ### Response: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(test)\n\u001b[1;32m     20\u001b[0m   input_ids \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m   generation_output \u001b[38;5;241m=\u001b[39m \u001b[43mre_model\u001b[49m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m     23\u001b[0m       input_ids\u001b[38;5;241m=\u001b[39minput_ids, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[1;32m     24\u001b[0m   )\n\u001b[1;32m     25\u001b[0m   predictions\u001b[38;5;241m.\u001b[39mappend(tokenizer\u001b[38;5;241m.\u001b[39mdecode(generation_output[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_response_text\u001b[39m(input_string):\n",
      "\u001b[0;31mNameError\u001b[0m: name 're_model' is not defined"
     ]
    }
   ],
   "source": [
    "# test fine-tuned model\n",
    "# Number 1000, 1001 from data.json\n",
    "test_strings = [\"Hello!\\nI am running a local instance of Galaxy (build 22.05). I installed the latest version of Deepvariant (1.4.0+galaxy0) which installed without any errors. However, when I try to run Deepvariant on BAM files output from HISAT2, the error “Fatal error: Exit code 127 ()” comes up. Further, it says that the tool generated the following error: “line 9: run_deepvariant: command not found”.\\nWhen I look at the backend to see what process Galaxy is going through, even after installation of the tool, the following line keeps repeating on the command line interface:\\nuvicorn.access INFO 2022-12-22 13:43:26,629 [pN:main.1,p:100965,tN:MainThread] 127.0.0.1:58158 - “GET /api/tool_shed_repositories?name=deepvariant&owner=iuc HTTP/1.1” 200\\nI don’t understand this error. Could someone please help me out?\\nI am running the same job on Galaxy.eu server and it is running (for a few hours now) but in the local instance in errors out pretty much instantly.\\nThanks!\",\n",
    "\"Dear Sir,\\nKindly help in this regards I was trying to make a de novo contig using trinity and it is running since from one week.\\nIs it ok??? or did I out something wrong\\nKindly help\",]\n",
    "\n",
    "#response_test_strings = [\n",
    "#\"Hello, I can’t give a full answer but I can maybe guide you in the right direction and maybe someone that can give a better answer will reply.\\nGiven the error it looks like deepvariant is not installed (not found). The tool is using a “docker tool dependency”, in other words it needs a container where deepvariant is installed. If you have not checked this yet then I think this is the place to start. Below two links where you may find some more information.\\nhttps://docs.galaxyproject.org/en/master/admin/special_topics/mulled_containers.html\\n  \\n      \\n\\n      training.galaxyproject.org\\n  \\n\\n  \\n    \\n\\nGalaxy Training: Tool Dependencies and Containers\\n\\n  Galaxy is an open-source project. Everyone can contribute...\\n\\n\\n  \\n\\n  \\n    \\n    \\n  \\n\\n  \\n\\n\\nThe requirement can be seen here:\\n  \\n\\n      github.com\\n  \\n\\n  \\n    galaxyproject/tools-iuc/blob/master/tools/deepvariant/macros.xml\\n\\n\\n      <macros>\\n    <token name=\"@TOOL_VERSION@\">1.4.0</token>\\n    <token name=\"@SUFFIX_VERSION@\">0</token>\\n    <xml name=\"edam_ontology\">\\n        <edam_topics>                                                                                  \\n            <edam_topic>topic_0199</edam_topic>\\n        </edam_topics>\\n        <edam_operations>\\n            <edam_operation>operation_3227</edam_operation>\\n        </edam_operations>\\n    </xml>\\n    <xml name=\"requirements\">\\n        <requirements>\\n            <container type=\"docker\">google/deepvariant:@TOOL_VERSION@</container>\\n        </requirements>\\n    </xml>\\n    <xml name=\"citations\">\\n        <citations>\\n            <citation type=\"doi\">10.1038/nbt.4235</citation>\\n        </citations>\\n\\n\\n\\n\\n  This file has been truncated. show original\\n\\n  \\n\\n  \\n    \\n    \\n  \\n\\n  \\n\\n\", \n",
    "# \"Hello @Sachin_Srivastava\\nIf the job is running (yellow/peach dataset), it is usually best to allow it to run. The same is true for queued jobs (grey dataset). This applies to jobs (any tool) executed at a public Galaxy server.\\n20 GB of fastq data – uncompressed – creates a very large assembly job. If it fails later on for exceeding resources (red dataset), you’ll need to do one or more of these:\\n\\nTry a rerun to eliminate cluster issues\\nMore QA/QC on the input reads (always recommended)\\nConsider downsampling the reads (tool: Seqtk)\\nPossibly need to move to your own Galaxy server where more resources can be allocated. The GVL version of Cloudman is one option: https://launch.usegalaxy.org/catalog\\n\\n\\nI added some tags to your post that will find prior Q&A about the above actions. Or, you can search the forum with those keywords (not all posts get tagged).\\nYou didn’t state where you are working. But, if by chance at Galaxy Main https://usegalaxy.org, I can let you know that the cluster that runs Trinity (and Unicycler + RNA-Star) is very busy. Longer queue times are expected. If you delete the current job and rerun, that will only place your job back at the end of the queue again, extending wait time.\\nThanks!\"]\n",
    "\n",
    "\n",
    "predictions = []\n",
    "for test in test_strings:\n",
    "  prompt = \"\"\" Below is an instruction that describes a task. Write a response that appropriately completes the request: \\n;\n",
    "\n",
    "  ### Instruction:\n",
    "  {}\n",
    "\n",
    "  ### Response: \\n\"\"\".format(test)\n",
    "    \n",
    "  input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to('cuda')\n",
    "\n",
    "  generation_output = re_model.generate(\n",
    "      input_ids=input_ids, max_new_tokens=256\n",
    "  )\n",
    "  predictions.append(tokenizer.decode(generation_output[0]))\n",
    "    \n",
    "\n",
    "def extract_response_text(input_string):\n",
    "    start_marker = 'Response:'\n",
    "    end_marker = '###'\n",
    "    start_index = input_string.find(start_marker)\n",
    "    if start_index == -1:\n",
    "        return None\n",
    "    \n",
    "    start_index += len(start_marker)\n",
    "    \n",
    "    end_index = input_string.find(end_marker, start_index)\n",
    "    if end_index == -1:\n",
    "        return input_string[start_index:]\n",
    "    \n",
    "    return input_string[start_index:end_index].strip()\n",
    "\n",
    "for i in range(len(test_strings)): \n",
    "  pred = predictions[i]\n",
    "  text = test_strings[i]\n",
    "  print(text+'\\n')\n",
    "  #print(pred+'\\n')\n",
    "  print(extract_response_text(pred))\n",
    "  print('--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c96a8e7-09fa-424e-a168-f8d939f8d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sentence = \"COVID-19 is\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\").input_ids.to('cuda')\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "#with torch.no_grad():\n",
    "beam_output = model.generate(input_ids=inputs,\n",
    "                            min_length=100,\n",
    "                            max_length=1024,\n",
    "                            num_beams=5,\n",
    "                            early_stopping=True\n",
    "                            )\n",
    "    \n",
    "output = tokenizer.decode(beam_output[0], skip_special_tokens=True)\n",
    "output\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fa68c52-a1c7-4c25-addb-9e64d10d4b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COVID-19 is a global pandemic caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), the causative agent of coronavirus disease 2019 (COVID-19), which has spread to more than 200 countries and territories, including the United States (US), Canada, Australia, New Zealand, the United Kingdom (UK), and the United States of America (USA), as of March 11, 2020, with more than 800,000 confirmed cases and more than 800,000 deaths.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc08706-39ca-419b-90e3-771631b0a325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
